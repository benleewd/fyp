{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extracting basic information sheet information first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "info = pd.read_excel('K11 Employment Particulars and Roaster (Cleaned).xlsx', 'Basic Information')\n",
    "\n",
    "info.fillna(value=\"NA\", inplace=True)\n",
    "\n",
    "def dummy(charvalue):\n",
    "    y = charvalue.replace(\"'\", \"\")\n",
    "    return y\n",
    "info['Highest_Qualification'] = info['Highest_Qualification'].apply(dummy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file = open(\"data extracted.sql\",\"a\")\n",
    "\n",
    "for index, row in info.iterrows():\n",
    "    # Employee basic information table\n",
    "    to_write = \"insert into Emp_Basic_Information (First_Name, Last_Name, Gender, Marital_Status, Date_Of_Birth, Nationality, Religion, Race, Blood_Group, Place_Of_Birth, Identification_Type, Identification_No, Pass_Type, Highest_Qualification, Mobile_No, Email, CREATED_BY) values ('\" + row['First_Name'] + \"', '\" + row['Last_Name'] + \"', '\" + row['Gender'] + \"', '\" + row['Marital_Status'] + \"', '\" + str(row['Date_Of_Birth']) + \"', '\" + row['Nationality'] + \"', '\" + row['Religion'] + \"', '\" + row['Race'] + \"', '\" + row['Blood_Group'] + \"', '\" + row['Place_Of_Birth'] + \"', '\" + row['Identification_Type'] + \"', '\" + str(row['Identification_No']) + \"', '\" + row['Pass_Type'] + \"', '\" + row['Highest_Qualification'] + \"', '\" + str(row['Mobile_No']) + \"', '\" + row['Email'] + \"' , 1);\\n\"\n",
    "    output_file.write(to_write)\n",
    "    \n",
    "    # Login Access table\n",
    "    to_write = \"insert into Login_Access (Employee_ID, Username, Password_Hashed, CREATED_BY) values ('\" + str(row['ID']) + \"', '\" + str(row['Identification_No']) + \"', \\\"\" + \"$2y$10$QuV6azSrw48E26.EZGjqOuj1jF0sIuk/fALR8qmATGvVEJr4H9CxW\" + \"\\\" , 1);\\n\"\n",
    "    output_file.write(to_write)\n",
    "    \n",
    "    # Telegram table\n",
    "    to_write = \"insert into Telegram (Employee_ID, Telegram_ID, Chat_ID, CREATED_BY) values ('\" + str(row['ID']) + \"', \" + \"Null\" + \", \" + \"Null\" + \" , 1);\\n\"\n",
    "    output_file.write(to_write)\n",
    "    \n",
    "    # Employee employment details table\n",
    "    to_write = \"insert into Emp_Employment_Details (Employee_ID, Joining_Date, Employment_Type, Designation, Department, CREATED_BY) values ('\" + str(row['ID']) + \"', '\" + str(row['Date Joined']) + \"', '\" + row['Full Time or Part Time'] + \"', '\" + \"Security Officer\" + \"', '\" + \"NA\" + \"' , 1);\\n\"\n",
    "    output_file.write(to_write)\n",
    "    \n",
    "    # Employee emergency contact table\n",
    "    to_write = \"insert into Emp_Emergency_Contact (Employee_ID, Emergency_Contact_Name, Relationship, Emergency_Contact_No, CREATED_BY) values ('\" + str(row['ID']) + \"', '\" + row['Emergency Contact Name'] + \"', '\" + row['Relationship'] + \"', '\" + str(row['Emergency Contact Number ']) + \"' , 1);\\n\"\n",
    "    output_file.write(to_write)\n",
    "    \n",
    "    \n",
    "output_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extracting schedule information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "schedule = pd.read_excel('K11 Employment Particulars and Roaster (Cleaned).xlsx', 'Feb 2020 (Adjusted)')\n",
    "schedule.drop([0, 1, 31, 32, 33, 34, 35, 36], axis=0, inplace=True)\n",
    "schedule.drop([schedule.columns[2], schedule.columns[3]], axis=1, inplace=True)\n",
    "schedule\n",
    "col_name = ['Site_ID', 'Location']\n",
    "partial_date_shift = \"2020-02-\"\n",
    "for i in range(1, 30):\n",
    "    day = str(i)\n",
    "    if len(day) == 1:\n",
    "        day = '0' + day\n",
    "    partial_date_shift += day + \"|day\" \n",
    "    col_name.append(partial_date_shift)\n",
    "    partial_date_shift = \"2020-02-\"\n",
    "    partial_date_shift += day + \"|night\" \n",
    "    col_name.append(partial_date_shift)\n",
    "    partial_date_shift = \"2020-02-\"\n",
    "\n",
    "schedule.columns = col_name\n",
    "schedule\n",
    "\n",
    "output_file = open(\"data extracted.sql\",\"a\")\n",
    "unique_site = []\n",
    "for index, row in schedule.iterrows():\n",
    "    if row['Site_ID'] not in unique_site:\n",
    "        unique_site.append(row['Site_ID'])\n",
    "        # Site table\n",
    "        to_write = \"insert into site (Project_Name, Shifts, Public_Holiday, Site_Allowance, Employees_Required, Active, CREATED_BY, Address) values ('\" + row['Location'] + \"', '\" + \"day and night\" + \"', \" + \"true\" + \", \" + \"0\" + \", \" + \"1\" + \", \" + \"true\" + \", \" + \"1\" + \", '\" + row['Location'] + \"');\\n\"\n",
    "        output_file.write(to_write)\n",
    "    \n",
    "unique_site = []\n",
    "for index, row in schedule.iterrows():\n",
    "    for index2, row2 in info.iterrows():\n",
    "        if row['Site_ID'] not in unique_site:\n",
    "            unique_site.append(row['Site_ID'])\n",
    "            # Schedule ranking table\n",
    "            to_write = \"insert into Schedule_Ranking (Employee_ID, Site_ID, Completed_Shift, CREATED_BY) values (\" + str(row2['ID']) + \", \" + str(row['Site_ID']) + \", \" + \"0\" + \", 1);\\n\"\n",
    "            output_file.write(to_write)\n",
    "\n",
    "for index, row in schedule.iterrows():\n",
    "    for date_shift in col_name:\n",
    "        if date_shift != 'Location' and date_shift != 'Site_ID':\n",
    "            date = date_shift.split('|')[0]\n",
    "            year = date.split('-')[0]\n",
    "            month = date.split('-')[1]\n",
    "            day = date.split('-')[2]\n",
    "            shift = date_shift.split('|')[1]\n",
    "            \n",
    "            person = row[date_shift]\n",
    "      \n",
    "            if type(person) == int:\n",
    "                # Schedule table\n",
    "                to_write = \"insert IGNORE into schedule (`Year`, `Month`, `Day`, Site_ID, Shift, Employee_ID, `CREATED_BY`) values ('\" + year + \"', '\" + month + \"', '\" + day + \"', '\" + str(row['Site_ID']) + \"', '\" + shift + \"', '\" + str(person) + \"' , 1);\\n\"\n",
    "                output_file.write(to_write)\n",
    "                \n",
    "                #Update schedule ranking table. Assumes shift is completed\n",
    "                to_write = \"update schedule_ranking set Completed_Shift = Completed_Shift + 1, LAST_MODIFIED_BY=1 where Employee_ID=\" + str(person) + \" and Site_ID=\" + str(row['Site_ID']) + \";\\n\"\n",
    "                output_file.write(to_write)\n",
    "            else:\n",
    "                # Schedule table\n",
    "                to_write = \"insert IGNORE into schedule (`Year`, `Month`, `Day`, Site_ID, Shift, Employee_ID, `CREATED_BY`) values ('\" + year + \"', '\" + month + \"', '\" + day + \"', '\" + str(row['Site_ID']) + \"', '\" + shift + \"', \" + \"1\" + \", 1);\\n\"\n",
    "                output_file.write(to_write)\n",
    "\n",
    "\n",
    "output_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
